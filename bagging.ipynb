{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from train import get_dataloaders, train_model, calculate_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = pd.read_csv(data_dir + 'train_data.csv')\n",
    "#augmented_train_data = pd.read_csv(data_dir + 'augmented_data_label_1_pegasus.csv')\n",
    "augmented_train_data = pd.read_csv(data_dir + 'augmented_data_label_1_parrot.csv')\n",
    "train_data = pd.concat([original_train_data, augmented_train_data], axis=0)\n",
    "\n",
    "val_data = pd.read_csv(data_dir + 'val_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 balanced sub-datasets for bagging\n",
    "num_sub_datasets = 2\n",
    "train_data_list = []\n",
    "\n",
    "ones = train_data[train_data['label'] == 1]\n",
    "zeros = train_data[train_data['label'] == 0]\n",
    "num = len(ones)\n",
    "\n",
    "for i in range(num_sub_datasets):\n",
    "    train_data_list.append(pd.concat([ones, zeros.sample(n=num, random_state=i)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data_list[0]['label'].value_counts())\n",
    "# print('Original train data shape: ', original_train_data.shape)\n",
    "# print('Concatenated train data shape: ', train_data.shape)\n",
    "# print(train_data_list[0])\n",
    "# print(original_train_data)\n",
    "# train_dataloader, val_dataloader = get_dataloaders(args, train_data_list[0], val_data)\n",
    "# o_train_dataloader, o_val_dataloader = get_dataloaders(args, original_train_data, val_data)\n",
    "# print(next(iter(train_dataloader)).keys())\n",
    "# print(next(iter(o_train_dataloader)).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "1. train the same model on 5 sub-datasets.\n",
    "2. predict labels using the 5 models (voting).\n",
    "3. calculate the accuracy and f1 score of the voting result.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "USE_LR_SCHEDULER = False\n",
    "PRETRAINED_MODEL_NAME = \"roberta-base\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "args = {\n",
    "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"USE_LR_SCHEDULER\": USE_LR_SCHEDULER,\n",
    "    \"PRETRAINED_MODEL_NAME\": PRETRAINED_MODEL_NAME,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels using the 5 models (voting)\n",
    "def predict(model_list, test_dataloader):\n",
    "    y_pred_list = []\n",
    "    for model in model_list:\n",
    "        model.eval()\n",
    "        # The list of predictions for each model\n",
    "        y_pred = []\n",
    "        for batch in test_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            # Extend every batch\n",
    "            y_pred.extend(logits.argmax(-1).cpu().numpy())\n",
    "        # Now we have a list of list of predictions\n",
    "        y_pred_list.append(y_pred)\n",
    "    # Voting\n",
    "    y_pred = np.array(y_pred_list).T\n",
    "    y_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=y_pred)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def calculate_bagging_f1(model_list, val_dataloader):\n",
    "    # Get the predictions\n",
    "    y_pred = predict(model_list, val_dataloader)\n",
    "    # Get the labels\n",
    "    y_true = np.array([])\n",
    "    for batch in val_dataloader:\n",
    "        y_true = np.concatenate((y_true, batch['labels'].numpy()))\n",
    "    # Calculate the f1 score\n",
    "    metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "    result_dict = metric.compute(predictions=y_pred, references=y_true)\n",
    "    return result_dict[\"f1\"]\n",
    "\n",
    "# If you need to load the models from disk here's your helper\n",
    "def load_models(num_models: int):\n",
    "    model_list = []\n",
    "    for i in range(num_models):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f\"bagging_model_{i}\", num_labels=2)\n",
    "        model_list.append(model)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01847de4e4784726a02803fff0dcf83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c041577f5c14e7d8cb577b532582f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.12058817595243454: 100%|██████████| 263/263 [06:22<00:00,  1.45s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3c6b13d4a2427ab6a625670307a570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f5f2fcaf924db08f11ef9bee9bc904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.09739437699317932: 100%|██████████| 263/263 [06:02<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Construct our \"bags\"\n",
    "model_list = []\n",
    "for i in range(num_sub_datasets):\n",
    "    print('Training model {}...'.format(i))\n",
    "    train_dataloader, val_dataloader = get_dataloaders(args, train_data_list[i], val_data)\n",
    "    model = train_model(args, device, train_dataloader, model_name = \"bagging_model_{}\".format(i))\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate f1 score\n",
      "[0.5352112676056339, 0.5016949152542373]\n",
      "Bagging f1 score\n",
      "0.5690376569037657\n"
     ]
    }
   ],
   "source": [
    "print(\"Separate f1 score\")\n",
    "list_of_metrics = []\n",
    "for i in range(num_sub_datasets):\n",
    "    metric = calculate_f1(f\"bagging_model_{i}\", device, val_dataloader)\n",
    "    list_of_metrics.append(metric)\n",
    "print(list_of_metrics)\n",
    "print(\"Bagging f1 score\")\n",
    "metric = calculate_bagging_f1(model_list, val_dataloader)\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf3454d8134cf31c53930b86a97c38f4c38d2a7205730a8063b2bb452273ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
